# -*- coding: utf-8 -*-
"""housing-prices-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jxkfyw7IXQzXJriCbPrv2mi4Y2woGSDJ
"""

!kaggle competitions download -c home-data-for-ml-course

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import RobustScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# Load Data
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

test_ids = test['Id']

# Delete outliers
train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)

y_train = np.log1p(train['SalePrice'])
train.drop(['SalePrice', 'Id'], axis=1, inplace=True)
test.drop(['Id'], axis=1, inplace=True)

ntrain = train.shape[0]
ntest = test.shape[0]
all_data = pd.concat((train, test)).reset_index(drop=True)

"""# Feature Engineering + Cleaning"""

# Fill NA Values
cols_none = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',
             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',
             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']
for col in cols_none:
  all_data[col] = all_data[col].fillna('None')


# We replace by median or average depending on the case
all_data['LotFrontage'] = all_data.groupby("Neighborhood")["LotFrontage"].transform(
    lambda x: x.fillna(x.median()))

for col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):
    all_data[col] = all_data[col].fillna(0)

# New features

all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']
all_data['YrBltAndRemod'] = all_data['YearBuilt'] + all_data['YearRemodAdd']
all_data['Total_Bathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) +
                               all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))



all_data = pd.get_dummies(all_data)

# Separation of train/test

X_train = all_data[:ntrain]
X_test = all_data[ntrain:]

"""# XGBoost"""

model_xgb = xgb.XGBRegressor(
    colsample_bytree=0.4603,
    gamma=0.0468,
    learning_rate=0.05,
    max_depth=3,
    min_child_weight=1.7817,
    n_estimators=2200,
    reg_alpha=0.4640,
    reg_lambda=0.8571,
    subsample=0.5213,
    random_state=7,
    n_jobs=-1
)

"""# Cross-validation"""

def rmsle_cv(model):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    rmse = np.sqrt(-cross_val_score(model, X_train, y_train, scoring="neg_mean_squared_error", cv=kf))
    return(rmse)

score = rmsle_cv(model_xgb)
print(f"\nScore XGBoost (CV RMSLE) : {score.mean():.4f} (std: {score.std():.4f})")


# Final training
model_xgb.fit(X_train, y_train)
xgb_pred = np.expm1(model_xgb.predict(X_test))

"""# Submission file"""

submission = pd.DataFrame()
submission['Id'] = test_ids
submission['SalePrice'] = xgb_pred
submission.to_csv('submission_xgb_powerful.csv', index=False)

print("File 'submission_xgb_powerful.csv' has been successfully generated !")